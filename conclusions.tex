\section{Conclusions} \label{sec:conclusions}

In this paper, we proposed a system for automatic music transcription which incorporated prior information from a polyphonic music prediction model based on recurrent neural networks. The acoustic transcription model was based on probabilistic latent component analysis, and information from the prediction system was incorporated using Dirichlet priors. Experimental results using the Bach10 dataset of multiple-instrument recordings showed that there is a clear and significant improvement (more than 2\% in terms of F-measure) by combining a music language model with an acoustic model for improving the performance of the latter.

In the future, we will evaluate the proposed system using language models trained from different sources. We will also investigate different system configurations, by bootstrapping the system for demonstrating that an improved transcription can lead to an improved prediction, and so on. Finally, ++(other prediction models?) 