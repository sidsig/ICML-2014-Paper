\section{Introduction} 
\label{sec:introduction}

Automatic Music Transcription (AMT) involves automatically generating a symbolic transcription of an acoustic musical signal. The transcription can be thought of as the digitized version of the musical score corresponding to the music signal. Typically, the output of an AMT systemis a \textit{pianoroll} representation, which is a two-dimensional matrix representation of a musical piece where the X-axis represents time quantized into regular intervals, and the Y-axis represents the $88$ keys of a piano in increasing pitch. A cell in this matrix is $1$ if the key represented by its X-coordinate is sounded at the time instant represented by its Y-coordinate.

\textit{NOTE: Automatic music transcription literature review, PLCA based AMT research and state-of-the-art techniques could go here. Consider citing work by Benetos, Nam, etc.}

There is no doubt that a reliable acoustic model is important for generating accurate symbolic transcriptions of a given music signal. %citation.
However, since music exhibits a fair amount of structural regularity much like language, it is natural for one to think of the possibility of improving transcription accuracy using a \textit{music language model} (MLM) in a manner akin to the use of a language model to improve the performance of a speech recognizer \cite{Rabiner1993}. In \cite{Boulanger-Lewandowski2012}, the predictions of a polyphonic MLM were used to this end. More generally, \textit{score informed} approaches have been found to benefit the performance of purely acoustic models in music research tasks such as source separation \cite{Ewert2012}, voice separation \cite{Ewert2011} and tonic identification \cite{Senturk2013}. % More references, if required: Source separation - Ganseman2010, Hennequin2011. Not sure how these examples are related to our work. 

In the present work, we make use of the predictions made by a Recurrent Neural Network-Neural Autoregressive Distribution Estimator (RNN-NADE) based polyphonic MLM proposed in \cite{Boulanger-Lewandowski2012} to refine the transcriptions of a PLCA based AMT system \cite{Benetos2012, Benetos2013}. \textit{NOTE: Summary of the combination strategy using Dirichlet priors, etc. could go here}. It was observed that combining the two models in this way boosts transcription accuracy to $100.00\%$ on the Bach-$10$ dataset, where the existing state-of-the-art accuracy is $99.00\%$.