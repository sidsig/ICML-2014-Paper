\section{Automatic Music Transcription System} \label{sec:transcription}


For combining acoustic and music language information in an automatic transcription context, we employ the transcription model of \cite{Benetos2012}, which supports the transcription of multiple-instrument polyphonic music and also supports pitch deviations or frequency modulations. The model of \cite{Benetos2012} is based on probabilistic latent component analysis (PLCA), which is a latent variable analysis method which has been used for decomposing spectrograms \cite{Shashanka2008} and can be viewed as a probabilistic version of non-negative matrix factorization \cite{Li1999}. For computational efficiency purposes, we employ the fast implementation from \cite{Benetos2013}, which utilized pre-extracted note templates that are also pre-shifted across log-frequency, in order to account for frequency modulations or tuning changes. In addition, as was shown in \cite{Smaragdis2009}, PLCA-based models can utilise priors for estimating unknown model parameters, which will be useful in this paper for informing the 
acoustic transcription system with symbolic information.

The transcription model takes as input a normalised log-frequency spectrogram $V_{\omega,t}$ ($\omega$ is the log-frequency index and $t$ is the time index) and approximates it as a bivariate probability distribution $P(\omega,t)$. $P(\omega,t)$ is decomposed into a series of log-frequency spectral templates per pitch, instrument, and log-frequency shifting (which indicates deviation with respect to the ideal tuning), as well as probability distributions for pitch, instrument, and tuning. 

The model is formulated as:
\begin{equation}
P(\omega,t) = P(t)\sum_{p,f,s}P(\omega|s,p,f)P_{t}(f|p)P_{t}(s|p)P_{t}(p) \label{eq:Model}
\end{equation} 
where $p$ denotes pitch, $s$ denotes the musical instrument source, and $f$ denotes log-frequency shifting (which indicates tuning/pitch deviations). $P(t)$ is the energy of the log-spectrogram, which is a known quantity. $P(\omega|s,p,f)$ denote pre-extracted log-spectral templates per pitch $p$ and instrument $s$, which are also pre-shifted across log-frequency. The pre-shifting operation is made in order to account for pitch deviations, without needing to formulate a convolutive model across log-frequency. $P_{t}(f|p)$ is the time-varying log-frequency shifting distribution per pitch, $P_{t}(s|p)$ is the time-varying source contribution per pitch, and finally, $P_{t}(p)$ is the pitch activation, which essentially is the resulting music transcription. As a time-frequency representation in the log-frequency domain we use the constant-Q transform (CQT) with a log-spectral resolution of 60 bins/octave \cite{Schoerkhuber10}.

The unknown model parameters ($P_{t}(f|p)$, $P_{t}(s|p)$, $P_{t}(p)$) can be iteratively estimated using the expectation-maximisation (EM) algorithm \cite{Dempster77}. For the \emph{Expectation} step, the following posterior is computed:
 \begin{equation}
  P_{t}(p,f,s|\omega) = \frac{P(\omega|s,p,f)P_{t}(f|p)P_{t}(s|p)P_{t}(p)}{\sum_{p,f,s}P(\omega|s,p,f)P_{t}(f|p)P_{t}(s|p)P_{t}(p)} \label{eq:EStep}
 \end{equation}
  
For the \emph{Maximization} step (without using any priors) unknown model parameters are updated using the posterior computed from the Expectation step:
 \begin{equation}
 P_{t}(f|p) = \frac{\sum_{\omega,s}P_{t}(p,f,s|\omega)V_{\omega,t}}{\sum_{f,\omega,s}P_{t}(p,f,s|\omega)V_{\omega,t}} 
\end{equation}
\begin{equation}
 P_{t}(s|p) = \frac{\sum_{\omega,f}P_{t}(p,f,s|\omega)V_{\omega,t}}{\sum_{s,\omega,f}P_{t}(p,f,s|\omega)V_{\omega,t}} \label{eq:MStepInstrument}
\end{equation}
\begin{equation}
 P_{t}(p) = \frac{\sum_{\omega,f,s}P_{t}(p,f,s|\omega)V_{\omega,t}}{\sum_{p,\omega,f,s}P_{t}(p,f,s|\omega)V_{\omega,t}} \label{eq:MStepTranscription}
\end{equation}


We consider the sound state templates to be fixed, so no update rule for $P(\omega|s,p,f)$ is applied. Using fixed templates, 20-30 iterations using the update rules presented in the present section are sufficient for convergence. The output of the system is a pitch activation which is scaled by the energy of the log-spectrogram:
\begin{equation}
P(p,t) =  P(t)P_{t}(p)\label{eq:transcription}
\end{equation}
After performing 5-sample median filtering for note smoothing, thresholding is performed on $P(p,t)$ followed by minimum note duration pruning set to 40ms (corresponding to the length of one time frame) in order to convert $P(p,t)$ into a binary piano-roll representation, which is the output of the transcription system, and is also used for evaluation purposes. 